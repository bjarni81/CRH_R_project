---
title: "Post-COVID: Deciding on cutoffs for PC CRH use"
date: "`r Sys.Date()`"
author: "Bjarni Haraldsson"
output: 
  html_document:
    code_folding: hide
    toc_float: true
    toc: true
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE, fig.width = 8, fig.height = 8)
#
# knitr::knit_hooks$set(inline = function(x){
#   prettyNum(x, big.mark = ",")
# })
#
options(scipen = 999, knitr.kable.NA = ' ')
#
library(tidyverse)
library(lubridate)
#library(gt)
library(kableExtra)
library(readxl)
library(DBI)
library(here)
library(scales)
library(janitor)
library(MatchIt)
library(lme4)
library(sjPlot)
#
##---------- Connection to SQL13
oabi_con <- dbConnect(odbc::odbc(),
                      Driver = "SQL Server",
                      Server = "vhacdwsql13.vha.med.va.gov",
                      Database = "OABI_MyVAAccess",
                      Trusted_Connection = "true")
#
`%ni%` <- negate(`%in%`)
#---------
theme_update(axis.title = element_text(size = 20),
             axis.text = element_text(size = 16),
             strip.text = element_text(size = 14),
             legend.text = element_text(size = 18),
             legend.title = element_blank(),
             plot.caption = element_text(size = 12),
             plot.title = element_text(size = 24),
             legend.position = "bottom")
#===========
source(here("input", "Functions", "multiplot_05jan21.R"))
```

```{r reading-in}
#vast file for s_abbr and others
vast <- dbGetQuery(oabi_con,
                   "select * from [OABI_MyVAAccess].[crh_eval].C2_vast_from_a06")
#making PC CRH criteria for this analysis
crh_flag <- dbGetQuery(oabi_con,
                       "select * from [crh_eval].C1_crh_flag") %>%
  left_join(., vast %>% select(sta5a, s_abbr))
#propensity score matched sta5as if being used
ps_matched <- read_csv(here("Input","Data", "ps_matched_sta5as_v6_post_COVID.csv"))
#pulling timely care
timely_care <- dbGetQuery(oabi_con,
                          "select *
                          from [OABI_MyVAAccess].[crh_eval].[E3_daysDV_month_sta5a]") %>%
  mutate(viz_month = ymd(viz_month)) %>%
  rename(sta5a = req_sta5a,
         vssc_month = viz_month)
#pulling vssc access metrics
access_metrics <- dbGetQuery(oabi_con,
                             "select * from [crh_eval].E2_VSSC_access_metrics") %>%
  mutate(vssc_month = ymd(vssc_month)) %>%
  left_join(timely_care)
#making a time column
dates <- tibble(
  vssc_month = seq.Date(ymd("2021-10-01"), ymd("2022-12-01"), "1 month")) %>%
  arrange(vssc_month) %>%
  rowid_to_column(., var = "time")
#counting average # of unique scrssns in FY2020 by sta5a and making a categorical variable
  # that we use for exclusion
scrssn_count <- dbGetQuery(oabi_con,
                           "with CTE as(
                            	select count(distinct ScrSSN_num) as scrssn_count
                            		, sta5a, fy, qtr
                            	from [PACT_CC].[econ].PatientPCP
                            	where fy = 2020
                            	group by Sta5a, fy, QTR
                            	)
                            select AVG(scrssn_count) as scrssn_count_avg_fy20, sta5a
                            from CTE
                            group by Sta5a") %>%
  mutate(scrssn_count_cat = factor(case_when(
    scrssn_count_avg_fy20 < 450 ~ "< 450",# exclusion criteria
    scrssn_count_avg_fy20 >= 450 & scrssn_count_avg_fy20 < 2400 ~ "450 - 2,399",
    scrssn_count_avg_fy20 >= 2400 & scrssn_count_avg_fy20 < 10000 ~ "2,400 - 9,999",
    scrssn_count_avg_fy20 >= 10000 ~ "10,000+"
  ), ordered = TRUE,
  levels = c("< 450", "450 - 2,399", "2,400 - 9,999", "10,000+")))
#---------------
covariates <- dbGetQuery(oabi_con,
                         "select * from [OABI_MyVAAccess].[crh_eval].Z_analytic_df") %>%
  rename(sta5a = Sta6a, vssc_month = visitMonth) %>%
  mutate(vssc_month = ymd(vssc_month)) %>%
  mutate(pct_male = male_count / scrssn_count * 100,
         pct_white = race_white_count / scrssn_count * 100,
         pct_rural = urh_rural_count / scrssn_count * 100) %>%
  select(pc_crh_per_1k_total_pc, #pcccr_per_10k_uniques,
         avg_age_oct1_2022, sta5a, vssc_month, 
         parent_visn, census_division,
         nosos_risk_score, obs_exp_panel_ratio, team_pcp_ap_fte_total,
         pcmm_count_fy_qtr,
         adi_natRnk_avg, pct_male, pct_white, pct_rural, avg_driveDist,
         shep_access_metric)
#------
pen_rate <- dbGetQuery(oabi_con,
                       "select *
                       from [OABI_MyVAAccess].[crh_eval].B1_crh_penRate") %>%
  rename(vssc_month = crh_month) %>%
  mutate(vssc_month = ymd(vssc_month))
```

```{r}
had_mt0_pccrh_after_sep_21 <- pen_rate %>%
  filter(vssc_month > ymd("2021-09-01")) %>%
  group_by(sta5a) %>%
  summarise(total_crh_enc = sum(crh_encounter_count, na.rm = T)) %>%
  filter(total_crh_enc > 0)
#--
met_criteria_after_sep_21 <- crh_flag %>%
  filter(had_pccrh_after_sep_21 == 1) %>%
  select(sta5a)
# 
all_crh_sta5as <- crh_flag %>%
  filter(had_pcCRH_after_march20 == 1) %>%
  select(sta5a)
#=================
#making the analytic dataset
analytic_df <- dates %>%
  cross_join(.,
            had_mt0_pccrh_after_sep_21 %>%
              select(sta5a)) %>% 
  left_join(., 
            pen_rate) %>%
  left_join(.,
            vast %>% select(sta5a, s_abbr)) %>%
  left_join(., scrssn_count) %>%
  filter(is.na(s_abbr) == F
         & scrssn_count_cat != "< 450") %>%
  mutate(crh_encounter_count2 = replace_na(crh_encounter_count, 0),
         pc_crh_per_1k_total_pc2 = replace_na(pc_crh_per_1k_total_pc, 0),
         crh_flag = if_else(sta5a %in% met_criteria_after_sep_21$sta5a, "PC CRH", "Not Enough PC CRH"),
         s_abbr2 = case_when(
           str_detect(s_abbr, "HCC|VAMC") == T ~ "HCC/VAMC",
           str_detect(s_abbr, "CBOC") == T ~ "CBOC",
           s_abbr == "OOS" ~ "OOS"
         )) %>%
  group_by(sta5a) %>%
  mutate(count_avg = mean(crh_encounter_count2, na.rm = T),
         rate_avg = mean(pc_crh_per_1k_total_pc2, na.rm = T)) %>%
  ungroup %>%
  mutate(count_cat = arules::discretize(count_avg,
                                        breaks = 3),
         rate_cat = arules::discretize(rate_avg,
                                       breaks = 3),
         count_4cat = arules::discretize(count_avg,
                                        breaks = 4),
         rate_4cat = arules::discretize(rate_avg,
                                       breaks = 4))
```

# Front Matter  

## Description of this report  

* This is an iteration on the task "identify natural groups of low, medium, and high users of PC CRH"

## Decision Points  

* While waiting for our whole team to be together so we can finalize the Pre-COVID analysis, this report is one piece of moving the Post-COVID analysis forward
    
## Analytic details  


* Description of the cohort (i.e., __analytic\_df__)
    + The first observation in the data occurs on `r min(analytic_df$vssc_month)`
    + The last observation in the data occurs on `r max(analytic_df$vssc_month)`
    + There are `r nrow(analytic_df) %>% comma()` rows in the data
    + These rows come from `r analytic_df %>% select(sta5a) %>% n_distinct()` sta5as
      + `r analytic_df %>% select(sta5a, crh_flag) %>% distinct() %>% summarise(tot = sum(crh_flag == "PC CRH"))` of these met our criteria for PC CRH after September 2021 
      + `r analytic_df %>% select(sta5a, s_abbr) %>% distinct() %>% summarise(tot = sum(str_detect(s_abbr, "CBOC") == T))` of these are CBOCs
      + `r analytic_df %>% select(sta5a, s_abbr) %>% distinct() %>% summarise(tot = sum(str_detect(s_abbr, "HCC|VAMC") == T))` of these are HCCs or VAMCs
      + `r analytic_df %>% select(sta5a, s_abbr) %>% distinct() %>% summarise(tot = sum(str_detect(s_abbr, "OOS") == T))` of these are OOS
    + Each row is a sta5a-month
    + There are `r nrow(dates)` months of observation

```{r table_fxns}
table_fxn <- function(covariate){
  analytic_df %>%
  summarise(avg_val = mean({{covariate}}, na.rm = T),
            sd_val = sd({{covariate}}, na.rm = T),
            qtl_25 = quantile({{covariate}},
                              0.25, 
                              na.rm = T),
            qtl_75 = quantile({{covariate}},
                              0.75, 
                              na.rm = T),
            min_val = min({{covariate}}, na.rm = T),
            max_val = max({{covariate}}, na.rm = T)) %>%
    mutate(avg_sd = paste0(comma(avg_val, accuracy = 0.1),
                           " (",
                           comma(sd_val, accuracy = 0.1),
                           ")"),
           qtls = paste0("[", comma(qtl_25, accuracy = 0.1),
                         ", ",
                         comma(qtl_75, accuracy = 0.1),
                         "]"),
           min_max = paste0("[", comma(min_val, accuracy = 0.1),
                            ", ",
                            comma(max_val, accuracy = 0.1),
                            "]")) %>%
    select(avg_sd, qtls, min_max) %>%
    kbl(col.names = c("Average (SD)", "[25th %-ile, 75th %-ile]", "[Minimum, Maximum]"),
        align = rep("c", 3)) %>%
    kable_classic() %>%
    row_spec(0, bold = TRUE)
}
#--
table_fxn_group <- function(covariate, group){
  analytic_df %>%
    filter(is.na({{group}}) == F) %>%
    group_by({{group}}) %>%
  summarise(avg_val = mean({{covariate}}, na.rm = T),
            sd_val = sd({{covariate}}, na.rm = T),
            qtl_25 = quantile({{covariate}},
                              0.25, 
                              na.rm = T),
            qtl_75 = quantile({{covariate}},
                              0.75, 
                              na.rm = T),
            min_val = min({{covariate}}, na.rm = T),
            max_val = max({{covariate}}, na.rm = T),
           n_group = comma(n(), accuracy = 1)) %>%
    mutate(avg_sd = paste0(comma(avg_val, accuracy = 0.1),
                           " (",
                           comma(sd_val, accuracy = 0.1),
                           ")"),
           qtls = paste0("[", comma(qtl_25, accuracy = 0.1),
                         ", ",
                         comma(qtl_75, accuracy = 0.1),
                         "]"),
           min_max = paste0("[", comma(min_val, accuracy = 0.1),
                            ", ",
                            comma(max_val, accuracy = 0.1),
                            "]")) %>%
    select({{group}}, n_group, avg_sd, qtls, min_max) %>%
    kbl(col.names = c("Group", "N", "Average (SD)", "[25th %-ile, 75th %-ile]", "[Minimum, Maximum]"),
        align = c("l", rep("c", 4))) %>%
    kable_classic() %>%
    row_spec(0, bold = TRUE)
}
```


# Let's Just Categorize Using Software?  

## 3 Groups  
### PC CRH Encounter Count - With Zeroes    
```{r}
table_fxn_group(crh_encounter_count2, count_cat)
```


```{r}
analytic_df %>%
ggplot(data = .,
       aes(x = crh_encounter_count2)) +
  geom_histogram() +
  facet_wrap(~count_cat) +
  labs(x = "PC CRH Encounters",
       y = "Sta5a-Months") +
  scale_y_continuous(labels = scales::comma_format(accuracy = 1))
```

### PC CRH Encounters per 1,000 Total PC Encounters - With Zeroes    
```{r}
table_fxn_group(pc_crh_per_1k_total_pc2, rate_cat)
```

```{r}
analytic_df %>%
ggplot(data = .,
       aes(x = pc_crh_per_1k_total_pc2)) +
  geom_histogram() +
  facet_wrap(~count_cat) +
  labs(x = "PC CRH Encounters per 1,000 Total PC",
       y = "Sta5a-Months") +
  scale_y_continuous(labels = scales::comma_format(accuracy = 1))
```

## 4 Groups  
### PC CRH Encounter Count - With Zeroes    
```{r}
table_fxn_group(crh_encounter_count2, count_4cat)
```


```{r}
analytic_df %>%
ggplot(data = .,
       aes(x = crh_encounter_count2)) +
  geom_histogram() +
  facet_wrap(~count_4cat) +
  labs(x = "PC CRH Encounters",
       y = "Sta5a-Months") +
  scale_y_continuous(labels = scales::comma_format(accuracy = 1))
```

### PC CRH Encounters per 1,000 Total PC Encounters - With Zeroes    
```{r}
table_fxn_group(pc_crh_per_1k_total_pc2, rate_4cat)
```

```{r}
analytic_df %>%
ggplot(data = .,
       aes(x = pc_crh_per_1k_total_pc2)) +
  geom_histogram() +
  facet_wrap(~count_4cat) +
  labs(x = "PC CRH Encounters per 1,000 Total PC",
       y = "Sta5a-Months") +
  scale_y_continuous(labels = scales::comma_format(accuracy = 1))
```

# Problem Sta5as  
```{r}
problem_sta5as <- analytic_df %>% 
  filter(sta5a %in% met_criteria_after_sep_21$sta5a 
         & crh_encounter_count > 0 
         & (is.na(pc_encounter_total) | pc_encounter_total == 0)) %>% 
  select(sta5a) %>% 
  distinct() %>%
  left_join(., vast %>% select(sta5a, parent_visn))
```

* There are `r nrow(problem_sta5as)` that pose a problem for the denominator in our rate:
    + They met our inclusion criteria after September 2021
    + They had at least one month where they had more than 0 PC CRH encounters AND exactly zero PC encounters 
* I think Thunderbird looks fine, but Rochester is a little more concerning
    
## (528GE) Rochester Clinton Crossings, NY    
```{r}
knitr::opts_chunk$set(
  knitr.kable.NA = "0"
)
#
analytic_df %>%
  left_join(., vast %>% select(sta5a, short_name, state)) %>%
  filter(sta5a == problem_sta5as[[1,1]]) %>%
  select(sta5a, vssc_month, crh_encounter_count, pc_encounter_total, s_abbr, short_name, state) %>%
  kbl(col.names = c("Sta5a", "Month", "PC CRH Encounters", "PC Encounters", "Site Type", "Name", "State")) %>%
  kable_classic("striped")
```

## (644GE) Thunderbird, AZ        
```{r}
knitr::opts_chunk$set(
  knitr.kable.NA = "0"
)
#
analytic_df %>%
  left_join(., vast %>% select(sta5a, short_name, state)) %>%
  filter(sta5a == problem_sta5as[[2,1]]) %>%
  select(sta5a, vssc_month, crh_encounter_count, pc_encounter_total, s_abbr, short_name, state) %>%
  kbl(col.names = c("Sta5a", "Month", "PC CRH Encounters", "PC Encounters", "Site Type", "Name", "State")) %>%
  kable_classic("striped")
```
